## Web Scraping Challenge

The objective of this challenge is to perform web scraping and data processing, from obtaining the information to its storage, using Python tools. 

### 1. Web scraping:
The first part will consist of generating the appropriate python code to extract data from an online source, for which at least two of the following APIS must be used:

- The NASA API allows you to use NASA data, its url is: https://api.nasa.gov/
    
- The Cocktail DB is an API that contains an open, crowdsourced database of drinks and cocktails from around the world. Its url is: https://www.thecocktaildb.com/
    
- Quotes API allows you to access multiple famous quotes. Its url is: https://quotes.rest/
    
- MovieDB API gives you all the data for many movies. Its url is: https://www.themoviedb.org/documentation/api

Once the two pages have been selected, it is important to take into account that it is necessary to extract both text and images.

### 2. Data processing:

The second stage of this challenge involves storing the information obtained in the previous stage. It is important that the teams use tools such as **MongoDB** or **Firebase** to store the extracted information in a cloud database.

### 3. Search engine:

Finally, the last stage is to generate a search engine with the information generated during the previous two stages. The user will be able to access this search engine and will be able to search for text or images about a topic, and the software will deliver all the data associated with such request.

## Submission Guidelines:

- Submit the complete python code used in algorithm development and the output images in a single tar ball.
- In such tar ball, include a single Jupyter notebook for external evaluation, ensuring proper comments.
- Clearly mention any external tools or packages used. Make sure they are publicly available and free.

## Evaluation
- Usability (20%): Your code should run smoothly, and its readability should be accessible to external evaluators.
- Interpretability (20%): Evaluation results should be quantitative and rigorous, providing a clear understanding of algorithm performance.
- Generalizability (40%): The code should work effectively on other similar data sets. The evaluators will test your code in different data sets.
- Performance (20%): Evaluation of the code's speed and efficiency.
  
